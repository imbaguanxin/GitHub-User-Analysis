---
title: "User_Analyse"
author: "ZiqianGe"
date: "4/7/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(mongolite)
library(tidyverse)
library(tidyverse)
library(class)
library(e1071)
library(MLmetrics)
```

```{r}
userdb_190401 <- mongo(db = "users", collection = "users_190401", url = "mongodb://127.0.0.1:27017")
repodb_190401 <- mongo(db = "repos", collection = "repos_190401", url = "mongodb://127.0.0.1:27017")
userdb_180415 <- mongo(db = "users", collection = "users_180415", url = "mongodb://127.0.0.1:27017")
repodb_180415 <- mongo(db = "repos", collection = "repos_180415", url = "mongodb://127.0.0.1:27017")
userdb_170415 <- mongo(db = "users", collection = "users_170415", url = "mongodb://127.0.0.1:27017")
repodb_170415 <- mongo(db = "repos", collection = "repos_170415", url = "mongodb://127.0.0.1:27017")
userdb_160415 <- mongo(db = "users", collection = "users_160415", url = "mongodb://127.0.0.1:27017")
repodb_160415 <- mongo(db = "repos", collection = "repos_160415", url = "mongodb://127.0.0.1:27017")
github_RepoUsers <- mongo(db = "github", collection = "repo_users", url = "mongodb://127.0.0.1:27017")
```
```{r}
userdb_190401$import(file("/Volumes/LaCie/MongoDB/db/dump_2019_04_01/github/users.bson"), bson = TRUE)
#repodb_190401$import(file("/Volumes/LaCie/MongoDB/db/dump_2019_04_01/github/repos.bson"), bson = TRUE)
#userdb_190401$import(file("~/overview-f17/MongoDB/db/dump_2019_04_01/github/users.bson"), bson = TRUE)
repodb_190401$import(file("~/overview-f17/MongoDB/db/dump_2019_04_01/github/repos.bson"), bson = TRUE)
userdb_180415$import(file("/Volumes/LaCie/MongoDB/db/dump_2018_04_15/github/users.bson"), bson = TRUE)
repodb_180415$import(file("/Volumes/LaCie/MongoDB/db/dump_2018_04_15/github/repos.bson"), bson = TRUE)
userdb_170415$import(file("/Volumes/LaCie/MongoDB/db/dump_2017_04_15/github/users.bson"), bson = TRUE)
repodb_170415$import(file("/Volumes/LaCie/MongoDB/db/dump_2017_04_15/github/repos.bson"), bson = TRUE)
userdb_160415$import(file("/Volumes/LaCie/MongoDB/db/dump_2016_04_15/github/users.bson"), bson = TRUE)
repodb_160415$import(file("/Volumes/LaCie/MongoDB/db/dump_2016_04_15/github/repos.bson"), bson = TRUE)
```

Language distribution in Apr. 1st, 2019.
```{r}
langs_190401 <- repodb_190401$find(fields = '{"_id" : false, "full_name" : true, "language" : true}')
cleanedLangs_190401 <- langs_190401 %>%
  na.omit() %>%
  distinct(full_name, .keep_all = TRUE) %>%
  group_by(language) %>%
  count() %>%
  arrange(desc(n))
cleanedLangs_190401$Percentage <- cleanedLangs_190401$n / sum(cleanedLangs_190401$n)
cleanedLangs_190401
ggplot(cleanedLangs_190401 %>% filter(Percentage > 0.01)) +
  geom_bar(mapping = aes(x = language, y = Percentage), stat = "identity") +
  theme(axis.text.x = element_text(vjust = 0.5, hjust = 1, angle = 90))
pieLangs_190406 <- cleanedLangs_190401 %>% head(10)
ggplot(pieLangs_190406, mapping = aes(x = "", y = Percentage, fill = language)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar(theta = "y") +
  theme_void()
```
```{r}
langs_180415 <- repodb_180415$find(fields = '{"_id" : false, "full_name" : true, "language" : true}')
cleanedLangs_180415 <- langs_180415 %>%
  na.omit() %>%
  distinct(full_name, .keep_all = TRUE) %>%
  group_by(language) %>%
  count() %>%
  arrange(desc(n))
cleanedLangs_180415$Percentage <- cleanedLangs_180415$n / sum(cleanedLangs_180415$n)
cleanedLangs_180415
```
```{r}
langs_170415 <- repodb_170415$find(fields = '{"_id" : false, "full_name" : true, "language" : true}')
cleanedLangs_170415 <- langs_170415 %>%
  na.omit() %>%
  distinct(full_name, .keep_all = TRUE) %>%
  group_by(language) %>%
  count() %>%
  arrange(desc(n))
cleanedLangs_170415$Percentage <- cleanedLangs_170415$n / sum(cleanedLangs_170415$n)
cleanedLangs_170415
```
```{r}
langs_160415 <- repodb_160415$find(fields = '{"_id" : false, "full_name" : true, "language" : true}')
cleanedLangs_160415 <- langs_160415 %>%
  na.omit() %>%
  distinct(full_name, .keep_all = TRUE) %>%
  group_by(language) %>%
  count() %>%
  arrange(desc(n))
cleanedLangs_160415$Percentage <- cleanedLangs_160415$n / sum(cleanedLangs_160415$n)
cleanedLangs_160415
ggplot(cleanedLangs_160415 %>% filter(Percentage > 0.01)) +
  geom_bar(mapping = aes(x = language, y = Percentage), stat = "identity") +
  theme(axis.text.x = element_text(vjust = 0.5, hjust = 1, angle = 90))
pieLangs_160415 <- cleanedLangs_160415 %>% head(10)
ggplot(pieLangs_160415, mapping = aes(x = "", y = Percentage, fill = language)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar(theta = "y") +
  theme_void()
```

```{r}
comparison <- cleanedLangs_190401 %>%
  inner_join(cleanedLangs_180415, by = "language") %>%
  inner_join(cleanedLangs_170415, by = "language") %>%
  inner_join(cleanedLangs_160415, by = "language")
colnames(comparison) <- c("language",
                          "190401", "Percentage_190401",
                          "180415", "Percentage_180415",
                          "170415", "Percentage_170415",
                          "160415", "Percentage_160415")
comparison <- comparison %>%
  arrange(desc(`Percentage_190401`
               + `Percentage_180415`
               + `Percentage_170415`
               + `Percentage_160415`))
comparison
comparison %>%
  filter(Percentage_190401 > 0.02) %>%
  gather(key = "date", value = "Percentage",
         -language, -`190401`, -`180415`, -`170415`, -`160415`) %>%
  ggplot(mapping = aes(x = language, y = Percentage, fill = date)) +
  geom_bar(width = 1, stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(vjust = 0.5, hjust = 1, angle = 90))
```

```{r}
cleanedLangs_190401 %>% with(wordcloud(language, n, max.words = 100, colors=brewer.pal(8, "Dark2")))
cleanedLangs_160415 %>% with(wordcloud(language, n, max.words = 100, colors=brewer.pal(8, "Dark2")))
```

```{r}
repoProperties_190401 <- repodb_190401$find(
  fields = '{"_id" : false, "full_name" : true, "language" : true, "stargazers_count" : true, "forks_count" : true, "open_issues_count" : true, "subscribers_count" : true}')
repoProperties_190401 <- repoProperties_190401 %>%
  na.omit() %>%
  distinct(full_name, .keep_all = TRUE) %>%
  filter((stargazers_count > 0)
         | (forks_count > 0)
         | (open_issues_count > 0)
         | (subscribers_count > 0)) %>%
  arrange(desc(stargazers_count + forks_count + open_issues_count + subscribers_count))
View(repoProperties_190401)
avgForks <- mean(repoProperties_190401$forks_count)
stdDevForks <- sd(repoProperties_190401$forks_count)
avgIssues <- mean(repoProperties_190401$open_issues_count)
stdDevIssues <- sd(repoProperties_190401$open_issues_count)
repoProperties_190401 %>%
  filter(forks_count > avgForks - 3 * stdDevForks & forks_count < avgForks + 3 * stdDevForks) %>%
  filter(open_issues_count > avgIssues - 3 * stdDevIssues & open_issues_count < avgIssues + 3 * stdDevIssues) %>%
  ggplot(mapping = aes(x = forks_count, y = open_issues_count)) +
  geom_point() +
  geom_smooth()
```

```{r}
normalize <- function(x) {
  numerator <- x
  denominator <- max(x)
  #print((numerator * 10) /denominator)
  return((numerator) /denominator)
}

#normalize_st <- function(source, target) {
#  combined <- c(target, source)
#  combined_normalized <- normalize(combined)
#  return(combined_normalized[1:length(target)])
#}

# formula to be changed
popularity_index <- function(repos) {
  pop_i <- (repos$stargazers_count + 1) %>% normalize()
  pop_i <- pop_i + ((repos$watchers_count + 1) %>% normalize())
  pop_i <- pop_i + ((repos$forks_count + 1) %>% normalize())
  pop_i <- pop_i + ((repos$open_issues_count + 1) %>% normalize())
  return(pop_i / 4)
}


```

```{r}
# repo_user <- get_repo_with_owner()
repo_input <- read.csv("repo_user.csv", stringsAsFactors = FALSE)

#repo_input$popularity_raw <- repo_input %>% popularity_index()
repo_input$popularity_normalized <- repo_input %>% popularity_index()
repo_input <- repo_input %>% na.omit()

avg_pi <- mean(repo_input$popularity_normalized)
std_pi <- sd(repo_input$popularity_normalized)
repo_input <- repo_input %>%
  filter(popularity_normalized <= avg_pi + 3 * std_pi | popularity_normalized <= avg_pi + 3 * std_pi)

possibleLanguage <- repo_input$language %>% unique()
training_set <- data.frame()
testing_set <- data.frame()
for (lan in possibleLanguage){
  df <- repo_input %>% filter(language == lan)
  testing_number <- sample(c(1:nrow(df)), size = floor(nrow(df) * 0.5), replace = FALSE)
  this_test <- df[testing_number,]
  this_train <- df[-testing_number,]
  testing_set <- testing_set %>% rbind(this_test)
  training_set <- training_set %>% rbind(this_train)
}


#training_set <- sample_frac(repo_input, 0.7)
#testing_set <- setdiff(repo_input, training_set)

#avg_pop_index <- c()
#for (userId in repo_input$owner) {
  #user_popularity_raw <- repo_input %>% filter(owner == userId) %>% popularity_index()
  #user_popularity_normlized <- normalize_st(repo_input$popularity_raw, user_popularity_raw)
  #avg_pop_index <- c(avg_pop_index, mean(user_popularity_normlized))
#}
#repo_input$owner_avg_pop_index <- avg_pop_index

model_lm_quantifiable <-
  lm(formula = popularity_normalized ~ public_repos + public_gists + followers + following,
             data = training_set)

model_glm_quantifiable <-
  glm(formula = popularity_normalized ~ public_repos + public_gists + followers + following,
             data = training_set,
             family = binomial)

model_lm <-
  lm(formula = popularity_normalized ~ public_repos + public_gists + followers + following + student + professor + engineer + university + language,
             data = training_set)

model_glm <-
  glm(formula = popularity_normalized ~ public_repos + public_gists + followers + following + student + professor + engineer + university + language,
             data = training_set,
             family = binomial)


summary(model_lm)
summary(model_glm)
step(model_glm)
```

Use linear regression on quantifiable columns only.
```{r}
probs <- predict(model_lm_quantifiable, newdata = testing_set, type = "response")
#head(testing_set$popularity_normalized)
#head(probs)
comparing <- data.frame(probs %>% as.vector(), testing_set$popularity_normalized)
colnames(comparing) <- c("prediction", "actual")
accuracies <- abs(probs - testing_set$popularity_normalized)/testing_set$popularity_normalized
accuracies[accuracies < 1] %>% length() / nrow(testing_set)
```

Use logistic regression on quantifiable columns only.
```{r}
probs <- predict(model_glm_quantifiable, newdata = testing_set, type = "response")
#head(testing_set$popularity_normalized)
#head(probs)
comparing <- data.frame(probs %>% as.vector(), testing_set$popularity_normalized)
colnames(comparing) <- c("prediction", "actual")
accuracies <- abs(probs - testing_set$popularity_normalized)/testing_set$popularity_normalized
accuracies[accuracies < 1] %>% length() / nrow(testing_set)
```

Use linear regression on all possible columns.
```{r}
probs <- predict(model_lm, newdata = testing_set, type = "response")
#head(testing_set$popularity_normalized)
#head(probs)
comparing <- data.frame(probs %>% as.vector(), testing_set$popularity_normalized)
colnames(comparing) <- c("prediction", "actual")
accuracies <- abs(probs - testing_set$popularity_normalized)/testing_set$popularity_normalized
accuracies[accuracies < 1] %>% length() / nrow(testing_set)
```

Use logistic regression on all possible columns.
```{r}
probs <- predict(model_glm, newdata = testing_set, type = "response")
#head(testing_set$popularity_normalized)
#head(probs)
comparing <- data.frame(probs %>% as.vector(), testing_set$popularity_normalized)
colnames(comparing) <- c("prediction", "actual")
accuracies <- abs(probs - testing_set$popularity_normalized)/testing_set$popularity_normalized
accuracies[accuracies < 1] %>% length() / nrow(testing_set)
```

```{r}
#training_set$language <- training_set$language %>% as.factor()
model_lm_student_quantifiable <-
  lm(formula = student ~ public_repos + public_gists + followers + following,
             data = training_set)

model_glm_student_quantifiable <-
  glm(formula = student ~ public_repos + public_gists + followers + following,
             data = training_set,
             family = binomial)

model_lm_student <-
  lm(formula = student ~ public_repos + public_gists + followers + following + professor + engineer + university,
             data = training_set)

model_glm_student <-
  glm(formula = student ~ public_repos + public_gists + followers + following + professor + engineer + university,
             data = training_set,
             family = binomial)

summary(model_lm_student_quantifiable)
summary(model_glm_student_quantifiable)
summary(model_lm_student_lang)
summary(model_glm_student_lang)
```

Use linear regression on quantifiable columns only.
```{r}
probs <- predict(model_lm_student, newdata = testing_set, type = "response") %>% as.vector()
#head(testing_set$popularity_normalized)
#head(probs)
preds <- ifelse(probs > 0.5, TRUE, FALSE)
comparing <- tibble(Probability = probs, Predict = preds, Actual = testing_set$student)
caret::confusionMatrix(factor(comparing$Predict), factor(comparing$Actual))
```

Use logistic regression on quantifiable columns only.
```{r}
probs <- predict(model_glm_student, newdata = testing_set, type = "response") %>% as.vector()
#head(testing_set$popularity_normalized)
#head(probs)
preds <- ifelse(probs > 0.5, TRUE, FALSE)
comparing <- tibble(Probability = probs, Predict = preds, Actual = testing_set$student)
caret::confusionMatrix(factor(comparing$Predict), factor(comparing$Actual))
```

Use linear regression on all possible columns.
```{r}
probs <- predict(model_lm_student_quantifiable, newdata = testing_set, type = "response") %>% as.vector()
#head(testing_set$popularity_normalized)
#head(probs)
preds <- ifelse(probs > 0.5, TRUE, FALSE)
comparing <- tibble(Probability = probs, Predict = preds, Actual = testing_set$student)
caret::confusionMatrix(factor(comparing$Predict), factor(comparing$Actual))
```

Use logistic regression on all possible columns.
```{r}
probs <- predict(model_glm_student_quantifiable, newdata = testing_set, type = "response") %>% as.vector()
#head(testing_set$popularity_normalized)
#head(probs)
preds <- ifelse(probs > 0.5, TRUE, FALSE)
comparing <- tibble(Probability = probs, Predict = preds, Actual = testing_set$student)
caret::confusionMatrix(factor(comparing$Predict), factor(comparing$Actual))
```

```{r}
probs <- predict(model_glm, newdata = testing_set, type = "response")
head(test_set$Survived)
head(probs)
```

```{r}
#repo_input%>% arrange(desc(popularity_normalized))
summary_users <- function(repo_in){
  users <- repo_in$owner %>% unique()
  users_summary <- data.frame()
  for (uid in users){
    df <- repo_in %>% filter(owner == uid)
    single_user_sum <- data.frame()
    id <- uid
    size <- df$size %>% mean()
    repo <- df$public_repos %>% mean()
    gist <- df$public_gists %>% mean()
    following <- df$following %>% mean()
    follower <- df$followers %>% mean()
    stargazer <- df$stargazers_count %>% mean()
    watcher <- df$watchers_count %>% mean()
    fork <- df$forks_count %>% mean()
    issue <- df$open_issues_count %>% mean()
    student <- df$student[1]
    professor <- df$professor[1]
    engineer <- df$engineer[1]
    university <- df$university[1]
    language <- df %>% group_by(language) %>% count() %>% arrange(desc(n))
    if (language %>% length > 0){
      language <- language %>% head(1)
      language <- language[1,1] %>% toString()
    } else {
      language <- NA
    }
    single_user_sum <- data.frame(id,size,repo,gist,following,follower,
                                  stargazer,watcher,fork,issue,language,
                                  student,professor,engineer,university)
    users_summary <- users_summary %>% rbind(single_user_sum)
  }
  return(users_summary)
}


user_training_set <- summary_users(training_set) %>% select(-language)%>% na.omit()
user_testing_set <- summary_users(testing_set) %>% select(-language) %>% na.omit()
# knn for students
pred1 <- knn(train = user_training_set %>% select(-c("id","professor","engineer","university")),
            test = user_testing_set%>% select(-c("id","professor","engineer","university")),
            cl = user_training_set$student %>% as.factor(), k = 3)
Accuracy(user_testing_set$student,pred1)
pred2 <- knn(train = user_training_set %>% select(-c("id","student","engineer","university")),
            test = user_testing_set%>% select(-c("id","student","engineer","university")),
            cl = user_training_set$professor %>% as.factor(), k = 3)
Accuracy(user_testing_set$student,pred2)
pred3 <- knn(train = user_training_set %>% select(-c("id","student","professor","university")),
            test = user_testing_set%>% select(-c("id","student","professor","university")),
            cl = user_training_set$engineer %>% as.factor(), k = 3)
Accuracy(user_testing_set$student,pred3)
pred4 <- knn(train = user_training_set %>% select(-c("id","student","professor","engineer")),
            test = user_testing_set%>% select(-c("id","student","professor","engineer")),
            cl = user_training_set$university %>% as.factor(), k = 3)
Accuracy(user_testing_set$student,pred4)
```
